# Prototypical Contrastive Learning V1 Configuration
# Sample weighting: weight_i = exp(-alpha * difficulty_i)

# Experiment name
experiment_name: "Prototypical_V1_MSPP"

# Task settings
task_type: "classification"
num_classes: 4

# Model settings
modality: "both"
audio_dim: 768
text_model_name: "bert-base-uncased"
freeze_text_encoder: true
text_max_length: 128
hidden_dim: 1024
dropout: 0.1

# Fusion settings
fusion_type: "cross_attention"
fusion_hidden_dim: 1024
num_attention_heads: 8

# Training settings
num_epochs: 30
batch_size: 32
learning_rate: 5e-5
weight_decay: 1e-4
val_split: 0.1

# Contrastive learning (ENABLED)
use_contrastive: true
contrastive_loss_type: "prototypical_v1"  # Sample weighting
contrastive_weight: 0.5  # Balance between classification and contrastive
contrastive_temperature: 0.07

# Prototypicality settings
prototypical_alpha: 1.0  # Weight decay for sample weighting
prototypical_beta: 0.5
prototypical_threshold: 1.0

# Dataset settings
train_dataset: "MSPP"
test_datasets: ["IEMO", "MSPI", "CMUMOSEI", "SAMSEMO"]

# Expected VAD values (normalized 0-1)

expected_vad:
  0: [0.4896, 0.5458, 0.5458]  # neutral
  1: [0.7127, 0.5518, 0.5518]  # happy
  2: [0.3060, 0.4895, 0.4895]  # sad
  3: [0.2397, 0.6102, 0.6102]  # anger
# WandB settings
wandb_project: "Emotion2Vec_Contrastive"
seed: 42
